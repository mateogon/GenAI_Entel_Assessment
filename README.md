# ü§ñ Assessment AI Engineer - An√°lisis Sem√°ntico de Transcripciones (Entel GenAI)

Este repositorio contiene la soluci√≥n para el assessment de AI Engineer del equipo GenAI de Entel. El proyecto implementa un sistema backend para analizar sem√°nticamente transcripciones de llamadas de atenci√≥n al cliente, utilizando la API de OpenAI de forma optimizada.

## üìù Descripci√≥n General

El sistema permite:

*   üîç **B√∫squeda:** Encontrar transcripciones relevantes mediante palabras clave o significado sem√°ntico.
*   üìä **Extracci√≥n de Temas:** Identificar los temas principales discutidos en una conversaci√≥n.
*   üè∑Ô∏è **Clasificaci√≥n Autom√°tica:** Asignar categor√≠as predefinidas (ej: "Problemas T√©cnicos", "Soporte Comercial") a las llamadas.

Se ha desarrollado priorizando la funcionalidad y una gesti√≥n eficiente del presupuesto de OpenAI ($5 USD).

## ‚ú® Caracter√≠sticas Principales

*   **Backend API:** Construido con FastAPI, proporcionando endpoints RESTful para b√∫squeda y an√°lisis.
*   **Procesamiento NLP:**
    *   Utiliza `text-embedding-3-small` de OpenAI para b√∫squeda sem√°ntica (generaci√≥n inicial offline, queries on-demand).
    *   Utiliza `gpt-4o-mini` de OpenAI para extracci√≥n de temas y clasificaci√≥n.
*   **Optimizaci√≥n de Costos:**
    *   Generaci√≥n √∫nica de embeddings para el dataset inicial.
    *   Modo de simulaci√≥n controlable (`ENABLE_OPENAI_CALLS` en `.env`) para desarrollo y pruebas sin consumir cr√©ditos de OpenAI para an√°lisis.
*   **Preprocesamiento:** Limpieza de texto, manejo de formato `.txt` de transcripciones y anonimizaci√≥n de PII (incluyendo RUT chileno) con Presidio.
*   **Interfaz Opcional:** Frontend b√°sico desarrollado con Streamlit para interactuar con la API.
*   **Documentaci√≥n API:** Auto-generada v√≠a Swagger UI (`/docs`) y ReDoc (`/redoc`).

## üõ†Ô∏è Configuraci√≥n del Entorno

Sigue estos pasos para configurar el proyecto localmente en Windows (usando PowerShell):

1.  **Clonar el Repositorio:**
    ```powershell
    git clone <url-del-repositorio>
    cd <nombre-del-repositorio> # Ej: GenAI_Entel_Assessment
    ```

2.  **Crear y Activar Entorno Virtual:**
    ```powershell
    python -m venv .venv
    # Podr√≠as necesitar ajustar la pol√≠tica de ejecuci√≥n:
    # Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
    .venv\Scripts\Activate.ps1
    # Deber√≠as ver (.venv) al inicio de tu prompt
    ```

3.  **Instalar Dependencias:**
    ```powershell
    pip install -r requirements.txt
    ```

4.  **Descargar Modelo de Lenguaje spaCy:** (Necesario para Presidio)
    ```powershell
    python -m spacy download es_core_news_md
    # Si usaste 'es_core_news_sm' en el c√≥digo, descarga ese en su lugar
    ```

5.  **Configurar API Key de OpenAI:**
    *   Crea un archivo llamado `.env` en la ra√≠z del proyecto.
    *   Abre `.env` con un editor y a√±ade tu clave de API:
        ```dotenv
        OPENAI_API_KEY=sk-TuClaveRealDeOpenAIaqui
        ```
    *   **(Importante)** Control del Modo de Simulaci√≥n:
        *   Para **deshabilitar** las llamadas reales a GPT (modo simulaci√≥n, **recomendado para probar**):
            ```dotenv
            # A√±ade o asegura que esta l√≠nea est√© presente y en false
            ENABLE_OPENAI_CALLS=false
            ```
        *   Para **habilitar** las llamadas reales a GPT (consumir√° cr√©ditos):
            ```dotenv
            # Cambia o a√±ade esta l√≠nea
            ENABLE_OPENAI_CALLS=true
            ```
        *   Si la l√≠nea `ENABLE_OPENAI_CALLS` no existe, por defecto operar√° en **modo simulaci√≥n** (`false`).

6.  **Colocar Datos Crudos:**
    *   Aseg√∫rate de que las 100 transcripciones en formato `.txt` (ej: `sample_01.txt`) est√©n dentro de la carpeta `data/raw/`.

## üöÄ Ejecuci√≥n

1.  **Preparar Datos (Ejecutar solo una vez inicialmente):**
    *   Abre PowerShell en la ra√≠z del proyecto (con el venv activado).
    *   **Paso 1: Preprocesamiento (Limpieza y Anonimizaci√≥n):**
        ```powershell
        python scripts/preprocess_data.py
        ```
        Esto leer√° los `.txt` de `data/raw/`, los limpiar√°/anonimizar√° y guardar√° archivos `.json` en `data/processed/`.
    *   **Paso 2: Generaci√≥n de Embeddings (Usa API OpenAI - bajo costo):**
        ```powershell
        python scripts/generate_embeddings_openai.py
        ```
        Esto generar√° los archivos `data/embeddings.npy` y `data/id_map.pkl`. Si ya existen, te preguntar√° si deseas sobrescribirlos (lo cual volver√≠a a usar la API de OpenAI). Responde 'y' solo si es necesario.

2.  **Iniciar el Backend (API FastAPI):**
    *   En la misma terminal (con venv activado):
        ```powershell
        uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
        ```
    *   La API estar√° disponible en `http://localhost:8000`.
    *   Puedes acceder a la documentaci√≥n interactiva en `http://localhost:8000/docs`.

3.  **Iniciar el Frontend (Streamlit - Opcional):**
    *   Abre OTRA terminal PowerShell en la ra√≠z del proyecto.
    *   Activa el entorno virtual: `.venv\Scripts\Activate.ps1`
    *   Ejecuta:
        ```powershell
        streamlit run frontend.py
        ```
    *   Se abrir√° autom√°ticamente una pesta√±a en tu navegador (usualmente `http://localhost:8501`).

## ‚öôÔ∏è Arquitectura y Decisiones T√©cnicas

*   **Backend:** FastAPI por su rendimiento, facilidad de uso y auto-documentaci√≥n OpenAPI.
*   **Procesamiento de Texto Crudo:** Scripts Python con `regex` para parsear el formato `.txt` y `Presidio` para una robusta anonimizaci√≥n de PII (incluyendo RUT chileno).
*   **Embeddings:** `text-embedding-3-small` de OpenAI por su balance costo/rendimiento. Se generan offline y se almacenan localmente (`.npy`) para minimizar costos de API en b√∫squedas posteriores. La similitud se calcula localmente (NumPy/Scikit-learn).
*   **An√°lisis (Temas/Clasificaci√≥n):** `gpt-4o-mini` de OpenAI por su capacidad de seguir instrucciones (prompting) para estas tareas con una configuraci√≥n r√°pida, usando prompts espec√≠ficos para cada tarea.
*   **Gesti√≥n de Presupuesto:** La estrategia clave es la generaci√≥n √∫nica de embeddings y el modo de simulaci√≥n para an√°lisis. Esto permite desarrollar y probar extensivamente sin apenas consumir el presupuesto. El gasto principal (y m√≠nimo) ocurre solo al generar los embeddings iniciales o al activar expl√≠citamente las llamadas reales para an√°lisis.
*   **Escalabilidad:** La soluci√≥n actual (carga en memoria) es adecuada para las 100 transcripciones del assessment. Para escalar a miles/millones, se recomendar√≠a:
    *   Usar una base de datos vectorial (ej: ChromaDB, Weaviate, Pinecone) para los embeddings.
    *   Almacenar los textos procesados en una base de datos NoSQL o un Data Lake.
    *   Implementar procesamiento batch para embeddings y an√°lisis si se usan APIs externas.
    *   Considerar alternativas open-source (ej: Sentence-Transformers, BERTopic, modelos de clasificaci√≥n de Hugging Face) para eliminar la dependencia y costo de APIs externas a gran escala.
*   **Frontend:** Streamlit por su rapidez para crear interfaces de datos directamente desde Python.

## üìñ Documentaci√≥n de la API

La documentaci√≥n interactiva de la API est√° disponible autom√°ticamente cuando el backend est√° corriendo:

*   **Swagger UI:** [http://localhost:8000/docs](http://localhost:8000/docs)
*   **ReDoc:** [http://localhost:8000/redoc](http://localhost:8000/redoc)

**Endpoints Principales:**

*   `POST /search/`: Realiza b√∫squedas.
    *   **Request Body:**
        ```json
        {
          "query": "texto a buscar",
          "search_type": "semantic" or "keyword",
          "top_n": 5 (opcional, default 5)
        }
        ```
    *   **Response Body (√âxito):**
        ```json
        {
          "results": [
            {"transcript_id": "sample_042", "score": 0.85}, // Score solo en sem√°ntica
            {"transcript_id": "sample_015", "score": 0.79},
            ...
          ]
        }
        ```
*   `POST /analyze/topics/`: Extrae temas.
    *   **Request Body:**
        ```json
        // Opci√≥n 1: Por ID
        {"transcript_id": "sample_007"}
        // Opci√≥n 2: Por Texto Directo
        {"text": "El cliente llam√≥ por problemas con su factura..."}
        ```
    *   **Response Body (√âxito):**
        ```json
        {"topics": ["Problema Facturaci√≥n", "Consulta Saldo"]}
        ```
*   `POST /analyze/classify/`: Clasifica la transcripci√≥n.
    *   **Request Body:** (Igual que para `/topics/`)
    *   **Response Body (√âxito):**
        ```json
        {"category": "Soporte Comercial"}
        ```
*   `GET /status`: Verifica el estado de la API.
    *   **Response Body (√âxito):**
        ```json
        {"status": "ok", "transcripts_loaded": 100}
        ```

## üí° Posibles Mejoras Futuras

*   Implementar cach√© para respuestas de an√°lisis de OpenAI.
*   Usar una base de datos vectorial para b√∫squeda sem√°ntica m√°s eficiente a gran escala.
*   Integrar modelos open-source para reducir dependencia y costos.
*   A√±adir m√°s m√©tricas y logging detallado.
*   Implementar pruebas automatizadas (unit, integration).
*   Mejorar la interfaz de usuario del frontend.

